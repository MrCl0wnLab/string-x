"""
M√≥dulo CLC para verifica√ß√£o de servidores HTTP/HTTPS.

Este m√≥dulo implementa um coletor que verifica a disponibilidade de servidores web
e coleta informa√ß√µes b√°sicas como status HTTP, t√≠tulo da p√°gina, servidores, redirecionamentos
e cabe√ßalhos de seguran√ßa.

√â √∫til para:
- Verificar se um host est√° ativo e respondendo em portas HTTP/HTTPS
- Coletar cabe√ßalhos de resposta para an√°lise
- Identificar tecnologias utilizadas pelo servidor
- Verificar redirecionamentos e configura√ß√µes de seguran√ßa
- Mapear a superf√≠cie de ataque de aplica√ß√µes web
"""
# Bibliotecas padr√£o
import re
import ssl
import socket

# Bibliotecas de terceiros
import httpx
import asyncio
from bs4 import BeautifulSoup

from typing import Dict, List, Any, Optional, Union
from urllib.parse import urlparse, urljoin

# M√≥dulos locais
from stringx.core.basemodule import BaseModule
from stringx.core.retry import retry_operation

class HttpProbe(BaseModule):
    """
    Coletor para verifica√ß√£o e an√°lise de servidores HTTP/HTTPS.
    
    Esta classe verifica a disponibilidade de servidores web, coleta informa√ß√µes
    sobre status HTTP, t√≠tulos, tecnologias e configura√ß√µes de seguran√ßa.
    
    Herda de BaseModule fornecendo interface padr√£o para m√≥dulos auxiliares.
    """
    
    def __init__(self):
        """
        Inicializa o verificador HTTP com configura√ß√µes padr√£o.
        """
        super().__init__()
        
        self.meta = {
            'name': 'HTTP Server Probe',
            'author': 'MrCl0wn',
            'version': '1.0',
            'description': 'Verifica disponibilidade e coleta informa√ß√µes de servidores HTTP/HTTPS',
            'type': 'collector',
            'example': './strx -l urls.txt -st "echo {STRING}" -module "clc:http_probe" -pm'
        }
        
        self.options = {
            'data': str(),          # URL ou dom√≠nio a ser verificado
            'timeout': 10,           # Timeout para requisi√ß√µes HTTP em segundos
            'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'follow_redirects': True,  # Seguir redirecionamentos
            'max_redirects': 5,       # M√°ximo de redirecionamentos a seguir
            'verify_ssl': False,      # Verificar certificados SSL
            'ports': [80, 443, 8080, 8443],  # Portas padr√£o a verificar
            'collect_headers': True,  # Coletar cabe√ßalhos importantes
            'collect_title': True,    # Extrair t√≠tulo da p√°gina
            'debug': False,           # Modo de debug
            'proxy': None,            # Proxy para requisi√ß√µes
            'retry': 3,               # N√∫mero de tentativas
            'retry_delay': None,         # Atraso entre tentativas (segundos)
        }
        
        # Cabe√ßalhos de seguran√ßa importantes para verifica√ß√£o
        self.security_headers = [
            'Content-Security-Policy',
            'Strict-Transport-Security',
            'X-Content-Type-Options',
            'X-Frame-Options',
            'X-XSS-Protection',
            'Referrer-Policy',
            'Permissions-Policy',
        ]
    
    def _normalize_url(self, url: str) -> List[str]:
        """
        Normaliza e formata URLs para verifica√ß√£o.
        
        Converte dom√≠nios em URLs completas (HTTP e HTTPS) e
        valida formatos de URL.
        
        Args:
            url: URL ou dom√≠nio a ser normalizado
            
        Returns:
            Lista de URLs normalizadas para testar
        """
        url = url.strip()
        urls_to_check = []
        
        # Se n√£o tiver um esquema, tente ambos HTTP e HTTPS
        if not url.startswith(('http://', 'https://')):
            # Verifica se parece um IP ou dom√≠nio
            if re.match(r'^[a-zA-Z0-9][-a-zA-Z0-9.]*\.[a-zA-Z]{2,}$', url) or \
               re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', url):
                ports = self.options.get('ports', [80, 443, 8080, 8443])
                
                # Adiciona HTTP para portas 80 e 8080
                if 80 in ports:
                    urls_to_check.append(f"http://{url}")
                if 8080 in ports:
                    urls_to_check.append(f"http://{url}:8080")
                
                # Adiciona HTTPS para portas 443 e 8443
                if 443 in ports:
                    urls_to_check.append(f"https://{url}")
                if 8443 in ports:
                    urls_to_check.append(f"https://{url}:8443")
            else:
                # Se n√£o parece um dom√≠nio ou IP v√°lido, tenta como est√°
                urls_to_check.append(url)
        else:
            # J√° tem esquema, usar como est√°
            urls_to_check.append(url)
            
        return urls_to_check
    
    def _extract_title(self, content: str) -> str:
        """
        Extrai o t√≠tulo de uma p√°gina HTML.
        
        Args:
            content: Conte√∫do HTML da p√°gina
            
        Returns:
            T√≠tulo extra√≠do ou string vazia se n√£o encontrado
        """
        try:
            soup = BeautifulSoup(content, 'html.parser')
            title = soup.title.string if soup.title else ""
            return title.strip() if title else ""
        except Exception as e:
            self.handle_error(e, "Erro ao extrair t√≠tulo da p√°gina")
            return ""
    
    @retry_operation
    async def _probe_url(self, url: str, client: httpx.AsyncClient) -> Dict[str, Any]:
        """
        Verifica uma URL e coleta informa√ß√µes.
        
        Args:
            url: URL a ser verificada
            client: Cliente HTTP ass√≠ncrono
            
        Returns:
            Dicion√°rio com informa√ß√µes coletadas
        """
        result = {
            'url': url,
            'status': None,
            'title': None,
            'server': None,
            'redirect_url': None,
            'security_headers': {},
            'error': None,
            'ip': None,
        }
        
        try:
            # Resolver IP do host
            parsed = urlparse(url)
            try:
                result['ip'] = socket.gethostbyname(parsed.netloc.split(':')[0])
            except socket.gaierror:
                result['ip'] = None
            
            # Fazer requisi√ß√£o HTTP
            response = await client.get(url)
            result['status'] = response.status_code
            
            # Verificar redirecionamento
            if response.is_redirect:
                redirect_url = response.headers.get('Location', '')
                if not redirect_url.startswith(('http://', 'https://')):
                    # Resolver URLs relativas
                    redirect_url = urljoin(url, redirect_url)
                result['redirect_url'] = redirect_url
            
            # Coletar cabe√ßalhos
            result['server'] = response.headers.get('Server', '')
            
            # Coletar cabe√ßalhos de seguran√ßa
            if self.options.get('collect_headers', True):
                for header in self.security_headers:
                    if header in response.headers:
                        result['security_headers'][header] = response.headers[header]
            
            # Extrair t√≠tulo se configurado e se for HTML
            if self.options.get('collect_title', True) and 'text/html' in response.headers.get('Content-Type', ''):
                result['title'] = self._extract_title(response.text)
            
            return result
        except httpx.HTTPError as e:
            result['error'] = f"Erro HTTP: {str(e)}"
            return result
        except Exception as e:
            result['error'] = f"Erro: {str(e)}"
            return result
    
    async def _probe_all_urls(self, urls: List[str]) -> List[Dict[str, Any]]:
        """
        Verifica v√°rias URLs de forma ass√≠ncrona.
        
        Args:
            urls: Lista de URLs a verificar
            
        Returns:
            Lista de resultados para cada URL
        """
        timeout = self.options.get('timeout', 10)
        user_agent = self.options.get('user_agent', 'Mozilla/5.0')
        verify_ssl = self.options.get('verify_ssl', False)
        max_redirects = self.options.get('max_redirects', 5) if self.options.get('follow_redirects', True) else 0
        proxy = self.options.get('proxy')
        
        # Configura√ß√µes de limites para clientes
        limits = httpx.Limits(max_keepalive_connections=5, max_connections=25)
        
        headers = {'User-Agent': user_agent}
        
        # Construir configura√ß√£o de cliente HTTP
        client_params = {
            'timeout': timeout,
            'follow_redirects': self.options.get('follow_redirects', True),
            'headers': headers,
            'limits': limits,
            'verify': verify_ssl,
        }
        
        # Adicionar proxy se configurado
        if proxy:
            client_params['proxies'] = proxy
        
        # Verificar URLs de forma ass√≠ncrona
        async with httpx.AsyncClient(**client_params) as client:
            tasks = [self._probe_url(url, client) for url in urls]
            results = []
            
            for task in tasks:
                try:
                    result = await task
                    results.append(result)
                except Exception as e:
                    self.handle_error(e, "Erro ao verificar URL")
        
        return results
        
    def _format_results(self, results: List[Dict[str, Any]]) -> str:
        """
        Formata os resultados das verifica√ß√µes para sa√≠da.
        
        Args:
            results: Lista de resultados de verifica√ß√µes
            
        Returns:
            String formatada com os resultados
        """
        output = []
        
        for result in results:
            status_str = f"{result['status']}" if result['status'] else "Error"
            
            # Determinar cor/s√≠mbolo com base no status
            if result.get('error'):
                status_indicator = "‚ùå"
            elif result['status'] and 200 <= result['status'] < 300:
                status_indicator = "‚úÖ"
            elif result['status'] and 300 <= result['status'] < 400:
                status_indicator = "‚Ü™Ô∏è"
            elif result['status'] and 400 <= result['status'] < 500:
                status_indicator = "‚ö†Ô∏è"
            elif result['status'] and 500 <= result['status'] < 600:
                status_indicator = "üî•"
            else:
                status_indicator = "‚ùì"
            
            # Formatar linha principal
            line = f"{status_indicator} {result['url']} ({status_str})"
            if result['ip']:
                line += f" - IP: {result['ip']}"
            output.append(line)
            
            # Adicionar detalhes
            if result['title']:
                output.append(f"   üìÑ T√≠tulo: {result['title']}")
            
            if result['server']:
                output.append(f"   üñ•Ô∏è Servidor: {result['server']}")
            
            if result['redirect_url']:
                output.append(f"   Redireciona para: {result['redirect_url']}")
            
            if result['security_headers']:
                headers_str = ", ".join([f"{k}: {v}" for k, v in result['security_headers'].items()])
                output.append(f"   üîí Headers de Seguran√ßa: {headers_str}")
            
            if result['error']:
                output.append(f"   Erro: {result['error']}")
            
            # Linha em branco entre resultados
            output.append("")
        
        return "\n".join(output).strip()
    
    async def _async_run(self) -> None:
        """
        Implementa√ß√£o ass√≠ncrona do m√©todo run.
        """
        try:
            target = self.options.get("data", "").strip()
            
            if not target:
                self.log_debug("Nenhum alvo especificado")
                return
            
            # Limpar resultados anteriores
            self._result[self._get_cls_name()].clear()
            
            self.log_debug(f"Verificando URL/host: {target}")
            
            # Normalizar URL(s)
            urls_to_check = self._normalize_url(target)
            if not urls_to_check:
                self.log_debug(f"Erro: URL inv√°lida: {target}")
                return
            
            self.log_debug(f"URLs a verificar: {', '.join(urls_to_check)}")
            
            # Verificar todas as URLs
            results = await self._probe_all_urls(urls_to_check)
            
            # Formatar e definir resultados
            if results:
                output = self._format_results(results)
                self.set_result(output)
            else:
                self.log_debug(f"‚ùì Sem resposta de {target}")
            
        except Exception as e:
            self.handle_error(e, "Erro HTTPProbe")
    
    def run(self) -> None:
        """
        Executa a verifica√ß√£o de servidor HTTP/HTTPS.
        
        Este m√©todo coordena todo o processo de verifica√ß√£o de URLs,
        incluindo normaliza√ß√£o, requisi√ß√µes ass√≠ncronas e formata√ß√£o
        dos resultados.
        
        Returns:
            None: Os resultados s√£o armazenados internamente atrav√©s do m√©todo set_result
        """
        
        
        # Obter loop de evento ou criar um novo
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # Executar o m√©todo ass√≠ncrono
        loop.run_until_complete(self._async_run())
